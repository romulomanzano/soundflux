{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a NN with Urban Sound Challenge Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background:**\n",
    "\n",
    "In parallel to the actuall fall detection experiment, we'll train a neural network leveraging the urban challenge dataset in order to develop the necessary libraries to map wav files to features (either MFCC or spectogram) and baseline the performance of the different approaches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from python_speech_features import mfcc\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import soundfile\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URBAN_SOUND_DIR = \"/media/nvidia/ROMULO'S/urban_sound_challenge/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sample WAV File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that features can be generated in a couple of ways\n",
    "\n",
    "* MFCC\n",
    "* Spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MFCCs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, sample_rate = soundfile.read(URBAN_SOUND_DIR+\"Train/5132.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_feat = mfcc(samples,sample_rate,nfft=2400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_feat.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spectrogram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/github/python_environments/soundflux/lib/python3.5/site-packages/scipy/signal/spectral.py:1970: UserWarning: nperseg = 256 is greater than input length  = 2, using nperseg = 2\n",
      "  .format(nperseg, input_length))\n"
     ]
    }
   ],
   "source": [
    "f, t, spectrogram= signal.spectrogram(samples,sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16573, 2, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrogram.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training using MFCC Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(URBAN_SOUND_DIR+'train.csv')\n",
    "test_df = pd.read_csv(URBAN_SOUND_DIR+'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mfcc(row,folder,nfft):\n",
    "    # fun\n",
    "    #ction to load files and extract features\n",
    "    file_name = os.path.join(URBAN_SOUND_DIR, folder, str(row.ID) + '.wav')\n",
    "   # handle exception to check if there isn't a file which is corrupted\n",
    "    try:\n",
    "        samples, sample_rate = soundfile.read(file_name)\n",
    "        # here kaiser_fast is a technique used for faster extraction\n",
    "        mfcc_feat = mfcc(samples,sample_rate,nfft=nfft)\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return pd.Series([None, None])\n",
    "    if folder == 'Test':\n",
    "        return pd.Series([mfcc_feat])\n",
    "    return pd.Series([mfcc_feat, row.Class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = train_df.apply(parse_mfcc,args=('Train',2400), axis=1)\n",
    "temp.columns = ['feature', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert temp.shape == (5435,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the classes and encode the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(temp['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['label_encoded'] = temp['label'].apply(classes.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the dataframe for future models/training sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_json(URBAN_SOUND_DIR+\"train_mfcc_transformed.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_json(URBAN_SOUND_DIR+\"train_mfcc_transformed.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEXT TEST THE JSON LOADING FORMAT!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp = pd.read_csv(URBAN_SOUND_DIR+\"train_mfcc_transformed.csv\", dtype={'feature': np.ndarray.dtype} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['feature', 'label', 'label_encoded'], dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate MFCC series into a single dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_avg = []\n",
    "for x in temp.feature.tolist():\n",
    "    X_avg.append(np.mean(x,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_avg[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X_avg)\n",
    "y = np.array(temp.label_encoded.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x.shape for x in X]) == set([(13,)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(13,)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(70, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4891 samples, validate on 544 samples\n",
      "Epoch 1/10\n",
      "4891/4891 [==============================] - 12s 3ms/step - loss: 0.3730 - acc: 0.8808 - val_loss: 0.4959 - val_acc: 0.8419\n",
      "Epoch 2/10\n",
      "4891/4891 [==============================] - 13s 3ms/step - loss: 0.3471 - acc: 0.8929 - val_loss: 0.5172 - val_acc: 0.8346\n",
      "Epoch 3/10\n",
      "4891/4891 [==============================] - 12s 3ms/step - loss: 0.3219 - acc: 0.9021 - val_loss: 0.5147 - val_acc: 0.8346\n",
      "Epoch 4/10\n",
      "4891/4891 [==============================] - 12s 2ms/step - loss: 0.2945 - acc: 0.9115 - val_loss: 0.5024 - val_acc: 0.8456\n",
      "Epoch 5/10\n",
      "4891/4891 [==============================] - 13s 3ms/step - loss: 0.2732 - acc: 0.9156 - val_loss: 0.5461 - val_acc: 0.8143\n",
      "Epoch 6/10\n",
      "4891/4891 [==============================] - 12s 2ms/step - loss: 0.2586 - acc: 0.9223 - val_loss: 0.5708 - val_acc: 0.8088\n",
      "Epoch 7/10\n",
      "4891/4891 [==============================] - 12s 3ms/step - loss: 0.2371 - acc: 0.9266 - val_loss: 0.5221 - val_acc: 0.8474\n",
      "Epoch 8/10\n",
      "4891/4891 [==============================] - 13s 3ms/step - loss: 0.2187 - acc: 0.9331 - val_loss: 0.5347 - val_acc: 0.8290\n",
      "Epoch 9/10\n",
      "4891/4891 [==============================] - 13s 3ms/step - loss: 0.1987 - acc: 0.9417 - val_loss: 0.5532 - val_acc: 0.8327\n",
      "Epoch 10/10\n",
      "4891/4891 [==============================] - 12s 3ms/step - loss: 0.1888 - acc: 0.9452 - val_loss: 0.5591 - val_acc: 0.8346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f20187550>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=10,batch_size=10,shuffle=False,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the model to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"./trained_models/hdf5/urban_sound_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize weights to HDF5\n",
    "model.save_weights(\"./trained_models/hdf5/urban_sound_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the MFCC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_temp = test_df.apply(parse_mfcc,args=('Test',4800), axis=1)\n",
    "test_temp.columns = ['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_temp.to_json(URBAN_SOUND_DIR+\"test_mfcc_transformed.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3297, 1)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_temp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Submission/ Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_avg = []\n",
    "for x in test_temp.feature.tolist():\n",
    "    X_test_avg.append(np.mean(x,axis=0))\n",
    "X_test = np.array(X_test_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3297"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['prediction'] = y_prediction.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_for_idx(cl):\n",
    "    return classes[cl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'street_music'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_for_idx(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Class'] = test_df['prediction'].apply(class_for_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(URBAN_SOUND_DIR+'test_prediction_baseline.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple model using spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_spec(row):\n",
    "    # fun\n",
    "    #ction to load files and extract features\n",
    "    folder = 'Train'\n",
    "    file_name = os.path.join(URBAN_SOUND_DIR, folder, str(row.ID) + '.wav')\n",
    "   # handle exception to check if there isn't a file which is corrupted\n",
    "    try:\n",
    "        samples, sample_rate = soundfile.read(file_name)\n",
    "        # here kaiser_fast is a technique used for faster extraction\n",
    "        f, t, spectrogram= signal.spectrogram(samples,sample_rate)\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return pd.Series([None, None])\n",
    "    return pd.Series([spectrogram, row.Class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>siren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>drilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>siren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID         Class\n",
       "0   0         siren\n",
       "1   1  street_music\n",
       "2   2      drilling\n",
       "3   3         siren\n",
       "4   4      dog_bark"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting features in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features for chunk # 0 of size 100\n",
      "Extracted features for chunk # 1 of size 100\n",
      "Extracted features for chunk # 2 of size 100\n",
      "Extracted features for chunk # 3 of size 100\n"
     ]
    }
   ],
   "source": [
    "chunk = 0\n",
    "chunk_size = 50\n",
    "for i in chunker(train_df,chunk_size):\n",
    "    temp_spec = i.apply(parser_spec, axis=1)\n",
    "    temp_spec.columns = ['feature', 'label']\n",
    "    temp_spec.to_json(URBAN_SOUND_DIR+\"train_spectrogram_transformed_chunk_{}.json\".format(chunk))\n",
    "    print(\"Extracted features for chunk # {} of size {}\".format(chunk,chunk_size))\n",
    "    chunk +=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
