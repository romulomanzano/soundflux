{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background:**\n",
    "\n",
    "The purpose of this notebook is to transform the .wav files captured by the SoundFlux team into a set of spectrograms.\n",
    "\n",
    "In addition, data will be augmented by overlaying different types of backrgound noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romulo/github/python_virtual_envs/soundflux/lib/python3.6/site-packages/librosa/cache.py:36: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if self.cachedir is not None:\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import soundfile\n",
    "from scipy import signal\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import specdisplay\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "from feature_generation import extract_spectrogram\n",
    "from scipy.io import wavfile\n",
    "import scipy.signal as sps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define file generation parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of Mel-frequencies to keep in the spectrograms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Files we'll do overlay with, and relevant parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#amplitude of overlay as a percentage of the fall\n",
    "power_scale_overlay = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_file_mapping = {'running_shower' : 'resampled_169659_shower.wav',\n",
    "               'children_playing' : 'resampled_children_ambiance.wav',\n",
    "               'group_talk':'resampled_group_talking.wav',\n",
    "               'white_noise_med_pitch':'resampled_white_noise_med_pitch.wav',\n",
    "               'white_noise_low_pitch':'resampled_white_noise_low_pitch.wav',\n",
    "               'background_music':'resampled_random_hip_hop.wav'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of randomly selected overlays per file\n",
    "overlays_per_overlay_file=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlay_scaler(normal_file, overlay_file,power_scale_overlay=0.2):\n",
    "    max_normal = max(np.max(normal_file),-np.min(normal_file))\n",
    "    max_overlay = max(np.max(overlay_file),-np.min(overlay_file))\n",
    "    scale_factor = (max_normal*power_scale_overlay)/ max_overlay\n",
    "    return scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_section_of_x_length(overlay_data, size):\n",
    "    starting_points = (overlay_data.shape[0]-size)\n",
    "    start = random.choice(range(0,starting_points+1))\n",
    "    subset = overlay_data[start:start+size]\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the PNG spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target folder where pull the original soundflux audio files from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_folder = \"/home/romulo/github/soundflux/samples\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all of the json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = [samples_folder+\"/\"+ f for f in listdir(samples_folder) if isfile(join(samples_folder, f)) and \".json\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error number 1\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "error_count = 0\n",
    "for fi in metadata:\n",
    "    log = open(fi, \"r\").read()\n",
    "    try:\n",
    "        d = json.loads(log)\n",
    "        if isinstance(d,dict):\n",
    "            data.append(d)\n",
    "    except Exception as e:\n",
    "        error_count +=1\n",
    "        print(\"Error number {}\".format(error_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder = \"/home/romulo/Documents/soundflux_augmented\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=True\n",
    "test_split = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save_spectrogram(y,sr,target_file):\n",
    "    #new plot\n",
    "    log_s = extract_spectrogram(y,sr,n_mels=n_mels,n_fft=2048)\n",
    "    fig = plt.figure(figsize=(12,4))\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "\n",
    "    #getting spectrogram\n",
    "    specdisplay.specshow(log_s, sr=sr, x_axis='time', y_axis='mel')\n",
    "\n",
    "    #Saving PNG\n",
    "    plt.savefig(target_file)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming file 0\n",
      "Transforming file 1\n",
      "Transforming file 2\n",
      "Transforming file 3\n",
      "Transforming file 4\n",
      "Transforming file 5\n",
      "Transforming file 6\n",
      "Transforming file 7\n",
      "Transforming file 8\n",
      "Transforming file 9\n",
      "Transforming file 10\n",
      "Transforming file 11\n",
      "Transforming file 12\n",
      "Transforming file 13\n",
      "Transforming file 14\n",
      "Transforming file 15\n",
      "Transforming file 16\n",
      "Transforming file 17\n",
      "Transforming file 18\n",
      "Transforming file 19\n",
      "Transforming file 20\n",
      "Transforming file 21\n",
      "Transforming file 22\n",
      "Transforming file 23\n",
      "Transforming file 24\n",
      "Transforming file 25\n",
      "Transforming file 26\n",
      "Transforming file 27\n",
      "Transforming file 28\n",
      "Transforming file 29\n",
      "Transforming file 30\n",
      "Transforming file 31\n",
      "Transforming file 32\n",
      "Transforming file 33\n",
      "Transforming file 34\n",
      "Transforming file 35\n",
      "Transforming file 36\n",
      "Transforming file 37\n",
      "Transforming file 38\n",
      "Transforming file 39\n",
      "Transforming file 40\n",
      "Transforming file 41\n",
      "Transforming file 42\n",
      "Transforming file 43\n",
      "Transforming file 44\n",
      "Transforming file 45\n",
      "Transforming file 46\n",
      "Transforming file 47\n",
      "Transforming file 48\n",
      "Transforming file 49\n"
     ]
    }
   ],
   "source": [
    "for index, row in dataset[::].iterrows():\n",
    "    print(\"Transforming file {}\".format(index))\n",
    "    if not os.path.exists(target_folder + \"/\"+'spectrograms'):\n",
    "        os.makedirs(target_folder + \"/\"+'spectrograms')\n",
    "    file_folder = str(target_folder+ \"/\"+'spectrograms')\n",
    "    if split:\n",
    "        if not os.path.exists(file_folder+ \"/\"+'split'):\n",
    "            os.makedirs(file_folder + \"/\"+'split')\n",
    "        #30% on testing\n",
    "        split_folder =file_folder+ \"/\"+'split'\n",
    "        if not os.path.exists(split_folder+ \"/\"+'train'):\n",
    "            os.makedirs(split_folder +\"/\"+'train')\n",
    "        if not os.path.exists(split_folder+ \"/\"+'test'):\n",
    "            os.makedirs(split_folder+ \"/\"+'test')\n",
    "        if random.randint(0,99) < test_split*100:\n",
    "            file_folder = split_folder + '/test'\n",
    "        else:\n",
    "            file_folder = split_folder + '/train'\n",
    "        \n",
    "        \n",
    "        \n",
    "    if not os.path.exists(file_folder + \"/\" + row['class']):\n",
    "        os.makedirs(file_folder + \"/\" + row['class'])\n",
    "    if not os.path.exists(file_folder + \"/overlay_noise\"):\n",
    "        os.makedirs(file_folder + \"/overlay_noise\")\n",
    "\n",
    "    # Convert to log scale (dB). We'll use the peak power as reference.\n",
    "    y, sr = soundfile.read(samples_folder + \"/\"+ str(row['audio_file']))\n",
    "    target_file_name = file_folder + '/' + row['class'] + '/' + row['id'] + '.png'\n",
    "    #save original spectrogram\n",
    "    create_and_save_spectrogram(y,sr,target_file_name)\n",
    "    #pick one channel from the recorded sample:\n",
    "    for k,v in overlay_file_mapping.items():\n",
    "        y_mono = np.squeeze(y[:,:1])\n",
    "        overlay_data, overlay_sampling_rate = soundfile.read(\"./overlay_files/{}\".format(v))\n",
    "        if overlay_sampling_rate != sr:\n",
    "            #assumes sr is greater\n",
    "            rate = int(sr/overlay_sampling_rate)\n",
    "            y_mono_base = sps.decimate(y_mono,3)\n",
    "        else:\n",
    "            y_mono_base = y_mono\n",
    "        for idx in range(0,overlays_per_overlay_file):\n",
    "            random_overlay = get_random_section_of_x_length(overlay_data, y_mono_base.shape[0])\n",
    "            scale_factor = get_overlay_scaler(y_mono_base,random_overlay,power_scale_overlay)\n",
    "            final_overlayed_data = np.add(y_mono_base,scale_factor*random_overlay)\n",
    "            #write to temp and read again, otherwise data is messed up\n",
    "            temp_overlay_wav_file = \"temp_overlay.wav\"\n",
    "            wavfile.write(temp_overlay_wav_file, overlay_sampling_rate, final_overlayed_data.T)\n",
    "            #read and generate spectrogram\n",
    "            combined_sound, combined_sample_rate = soundfile.read(temp_overlay_wav_file)\n",
    "            overlayed_target_file_name = file_folder + '/' + row['class'] + '/' + row['id'] + '_{}_{}_overlay.png'.format(k,idx)\n",
    "            create_and_save_spectrogram(combined_sound,combined_sample_rate,overlayed_target_file_name)\n",
    "            #save original overlay too!\n",
    "            overlay_target_file_name = file_folder + '/' + \"overlay_noise\" + '/' + row['id'] + '{}_{}_overlay_only.png'.format(k,idx)\n",
    "            create_and_save_spectrogram(random_overlay,overlay_sampling_rate,overlay_target_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
